# Hindsight Experience Replay

OpenAI's Mar 2018 request for research highlighted the research trajectory of combining HER with other advances in RL. The goal of HER Variations is to explore these possibilities. 

Requires baselines, which can be installed here: https://github.com/openai/baselines

## TODO

- [ ] Combine PPO with experience replay
- [ ] Add IPG
- [ ] Build HER roadmap based on paper
- [ ] Extend to hindsight experience replay

## Resources

* [Great intro article](https://becominghuman.ai/learning-from-mistakes-with-hindsight-experience-replay-547fce2b3305)
* [More papers than there is time to read](https://github.com/junhyukoh/deep-reinforcement-learning-papers)
* I finally stopped and read this helpful [Reinforcement Learning (Sutton & Barto) textbook](https://www.amazon.com/Reinforcement-Learning-Introduction-Adaptive-Computation/dp/0262193981/ref=sr_1_3?ie=UTF8&qid=1524087150&sr=8-3&keywords=reinforcement+learning)
* Steve Brunton's awesome [Control Bootcamp](https://www.youtube.com/channel/UCm5mt-A4w61lknZ9lCsZtBw)
* Brian Douglas' control [playlist](https://www.youtube.com/watch?v=oBc_BHxw78s&list=PLUMWjy5jgHK1NC52DXXrriwihVrYZKqjk)
* Emma Brunskill's [talks](https://www.youtube.com/watch?v=fIKkhoI1kF4&list=PLAsrlO2SCuzBVqN6V1CQSL4VdaGv7LawW) at Simons Institute
* [Deep RL Bootcamp](https://sites.google.com/view/deep-rl-bootcamp/lectures)
* [HER Variation with PPO](https://github.com/jianing-sun/Interpolated-Policy-Gradient-with-PPO-for-Robotics-Control-/tree/master/Hindsight_ExperienceReplay)

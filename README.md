# HER Variations

OpenAI's Mar 2018 request for research highlighted the research trajectory of combining HER with other advances in RL. The goal of HER Variations is to explore these possibilities. 

Requires baselines, which can be installed here: https://github.com/openai/baselines

## Combinations

* Deep Q-Learning with HER (HER-DQN) 
* Deep Deterministic Policy Gradients with HER (HER-DDPG) 
* Proximal Policy Optimization with HER (HER-PPO)

## Resources

* [Great intro article](https://becominghuman.ai/learning-from-mistakes-with-hindsight-experience-replay-547fce2b3305)
* [More papers than there is time to read](https://github.com/junhyukoh/deep-reinforcement-learning-papers)
* I finally stopped and read this helpful [Reinforcement Learning (Sutton & Barto) textbook](https://www.amazon.com/Reinforcement-Learning-Introduction-Adaptive-Computation/dp/0262193981/ref=sr_1_3?ie=UTF8&qid=1524087150&sr=8-3&keywords=reinforcement+learning)
* Steve Brunton's awesome [Control Bootcamp](https://www.youtube.com/channel/UCm5mt-A4w61lknZ9lCsZtBw)
* Brian Douglas' control [playlist](https://www.youtube.com/watch?v=oBc_BHxw78s&list=PLUMWjy5jgHK1NC52DXXrriwihVrYZKqjk)
* Emma Brunskill's [talks](https://www.youtube.com/watch?v=fIKkhoI1kF4&list=PLAsrlO2SCuzBVqN6V1CQSL4VdaGv7LawW) at Simons Institute
* [Deep RL Bootcamp](https://sites.google.com/view/deep-rl-bootcamp/lectures)
